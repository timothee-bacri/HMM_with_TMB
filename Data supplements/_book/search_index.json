[["confidence-intervals.html", "Chapter 5 Confidence intervals 5.1 Generating data 5.2 Relabeling HMM states 5.3 Bootstrap code", " Chapter 5 Confidence intervals From the parameters ML estimates, we generate new data and re-estimate the parameters times. From that list of new estimates we can get the 2.5th and 97.5th percentiles and get 95% confidence intervals for the parameters.\\ We show below how we get confidence intervals using bootstrap, based on the 2 state Poisson HMM estimates from above. 5.1 Generating data First, we need a function to generate random data from a HMM. # Generate a random sample from a HMM pois.HMM.generate_sample &lt;- function(ns, mod) { mvect &lt;- 1:mod$m state &lt;- numeric(ns) state[1] &lt;- sample(mvect, 1, prob = mod$delta) for (i in 2:ns) { state[i] &lt;- sample(mvect, 1, prob = mod$gamma[state[i - 1], ]) } x &lt;- rpois(ns, lambda = mod$lambda[state]) return(list(data = x, state = state)) } In practice, it happens that HMMs cannot be estimated on generated samples. To deal with this issue, we can generate a new sample as long as HMMs cannot be estimated on it with the help of this more robust function which can easily be adapted to different needs. # Generate a random sample from a HMM pois.HMM.generate_estimable_sample &lt;- function(ns, mod, testing_params, params_names = PARAMS_NAMES, test_marqLevAlg = FALSE, std_error = FALSE) { if(anyNA(c(ns, mod, testing_params))) { stop(&quot;Some parameters are missing in pois.HMM.generate_estimable_sample&quot;) } # Loop as long as there is an issue with nlminb repeat { mod_temp &lt;- NULL #simulate the data new_data &lt;- pois.HMM.generate_sample(ns = ns, mod = mod) TMB_benchmark_data &lt;- list(x = new_data$data, m = mod$m) testing_w_params &lt;- pois.HMM.pn2pw(m = mod$m, lambda = testing_params$lambda, gamma = testing_params$gamma, delta = testing_params$delta) # Test TMB suppressWarnings(mod_temp &lt;- TMB.estimate(TMB_data = TMB_benchmark_data, parameters = testing_w_params, std_error = std_error)) # If nlminb doesn&#39;t reach any result, retry if (is.null(mod_temp)) { next } # If nlminb doesn&#39;t converge successfully, retry if (mod_temp$convergence != 0) { next } # Test TMB_G suppressWarnings(mod_temp &lt;- TMB.estimate(TMB_data = TMB_benchmark_data, parameters = testing_w_params, gradient = TRUE, std_error = std_error)) # If nlminb doesn&#39;t reach any result, retry if (is.null(mod_temp)) { next } # If nlminb doesn&#39;t converge successfully, retry if (mod_temp$convergence != 0) { next } # Test TMB_H suppressWarnings(mod_temp &lt;- TMB.estimate(TMB_data = TMB_benchmark_data, parameters = testing_w_params, hessian = TRUE, std_error = std_error)) # If nlminb doesn&#39;t reach any result, retry if (is.null(mod_temp)) { next } # If nlminb doesn&#39;t converge successfully, retry if (mod_temp$convergence != 0) { next } # Test TMB_GH suppressWarnings(mod_temp &lt;- TMB.estimate(TMB_data = TMB_benchmark_data, parameters = testing_w_params, gradient = TRUE, hessian = TRUE, std_error = std_error)) # If nlminb doesn&#39;t reach any result, retry if (is.null(mod_temp)) { next } # If nlminb doesn&#39;t converge successfully, retry if (mod_temp$convergence != 0) { next } # Test marqLevAlg # marqLevAlg sometimes doesn&#39;t converge either if (test_marqLevAlg == TRUE) { testing_w_params &lt;- unlist(testing_w_params) # No need to spend a few seconds to compute the marqLevAlg optimization if it&#39;s unnecessary if (marqLevAlg(b = testing_w_params, fn = mod_temp$obj$fn, gr = mod_temp$obj$gr, hess = mod_temp$obj$he, maxiter = 10000)$istop != 1) { next } } l &lt;- mod_temp$lambda g &lt;- mod_temp$gamma d &lt;- mod_temp$delta l_se &lt;- mod_temp$lambda_std_error g_se &lt;- mod_temp$gamma_std_error d_se &lt;- mod_temp$delta_std_error # Label switching natural_parameters &lt;- pois.HMM.label.order(m, lambda = l, gamma = g, delta = d, lambda_std_error = l_se, gamma_std_error = g_se, delta_std_error = d_se) # If some parameters are NA for some reason, retry if (anyNA(natural_parameters[params_names], recursive = TRUE)) { next } # If everything went well, end the &quot;repeat&quot; loop break } return(c(data = list(new_data$data), natural_parameters = list(natural_parameters), mod = list(mod_temp))) } 5.2 Relabeling HMM states When the model is estimated each time, we dont impose by default an order for the states. This can lead to the label switching problem, where states arent ordered the same way in each model. To address this, we re-ordered the states by ascending Poisson means. Sorting the means is direct, however re-ordering the TPM is not as straightforward. To do so, we take the permutations of the states given by the sorted Poisson means, and permute each row index and column index to its new value. A function to achieve this is # Relabel states by increasing Poisson means pois.HMM.label.order &lt;- function(m, lambda, gamma, delta = NULL, lambda_std_error = NULL, gamma_std_error = NULL, delta_std_error = NULL) { # Get the indexes of the sorted states # according to ascending lambda # sorted_lambda contains the permutations needed sorted_lambda &lt;- sort(lambda, index.return = TRUE)$ix ordered_lambda &lt;- lambda[sorted_lambda] # Re-order the TPM according to the switched states # in the sorted lambda ordered_gamma &lt;- matrix(0, nrow = m, ncol = m) for (col in 1:m) { new_col &lt;- which(sorted_lambda == col) for (row in 1:m) { new_row &lt;- which(sorted_lambda == row) ordered_gamma[row, col] &lt;- gamma[new_row, new_col] } } # Same for the TPM&#39;s standard errors ordered_gamma_std_error &lt;- NULL if (!is.null(gamma_std_error)) { ordered_gamma_std_error &lt;- matrix(0, nrow = m, ncol = m) for (col in 1:m) { new_col &lt;- which(sorted_lambda == col) for (row in 1:m) { new_row &lt;- which(sorted_lambda == row) ordered_gamma_std_error[row, col] &lt;- gamma_std_error[new_row, new_col] } } } # Re-order the stationary distribution if it is provided # Generate it otherwise if (is.null(delta)) { ordered_delta &lt;- stat.dist(ordered_gamma) } else { ordered_delta &lt;- delta[sorted_lambda] } # Re-order the standard errors ordered_lambda_std_error &lt;- lambda_std_error[sorted_lambda] ordered_delta_std_error &lt;- delta_std_error[sorted_lambda] result &lt;- list(lambda = ordered_lambda, gamma = ordered_gamma, delta = ordered_delta, lambda_std_error = ordered_lambda_std_error, gamma_std_error = ordered_gamma_std_error, delta_std_error = ordered_delta_std_error) # Remove the NULL elements result[sapply(result, is.null)] &lt;- NULL return(result) } Lets show an example to understand the process. For readability, the TPM is filled with row and column indexes instead of probabilities. lambda &lt;- c(30, 10, 20) gamma &lt;- matrix(c(11, 12, 13, 21, 22, 23, 31, 32, 33), byrow = TRUE, ncol = 3) pois.HMM.label.order(m = 3, lambda, gamma) ## $lambda ## [1] 10 20 30 ## ## $gamma ## [,1] [,2] [,3] ## [1,] 33 31 32 ## [2,] 13 11 12 ## [3,] 23 21 22 ## ## $delta ## [1] -0.032786885 0.016393443 -0.008196721 State 1 has been relabeled state 3, state 3 became state 2, and state 2 became state 1. 5.3 Bootstrap code set.seed(123) library(TMB) TMB::compile(&quot;code/poi_hmm.cpp&quot;) dyn.load(dynlib(&quot;code/poi_hmm&quot;)) source(&quot;functions/utils.R&quot;) m &lt;- 2 load(&quot;data/tinnitus.RData&quot;) TMB_data &lt;- list(x = tinn_data, m = m) # Initial set of parameters lambda_init &lt;- c(1, 3) gamma_init &lt;- matrix(c(0.8, 0.2, 0.2, 0.8), byrow = TRUE, nrow = m) # Turn them into working parameters parameters &lt;- pois.HMM.pn2pw(m, lambda_init, gamma_init) # Build the TMB object obj_tmb &lt;- MakeADFun(TMB_data, parameters, DLL = &quot;poi_hmm&quot;, silent = TRUE) # Optimize mod_tmb &lt;- nlminb(start = obj_tmb$par, objective = obj_tmb$fn, gradient = obj_tmb$gr, hessian = obj_tmb$he) # Bootstrap procedure bootstrap_estimates &lt;- data.frame() DATA_SIZE &lt;- length(tinn_data) # Set how many parametric bootstrap samples we create BOOTSTRAP_SAMPLES &lt;- 10 # MLE ML_working_estimates &lt;- obj_tmb$env$last.par.best ML_natural_estimates &lt;- obj_tmb$report(ML_working_estimates) lambda &lt;- ML_natural_estimates$lambda gamma &lt;- ML_natural_estimates$gamma delta &lt;- ML_natural_estimates$delta PARAMS_NAMES &lt;- c(&quot;lambda&quot;, &quot;gamma&quot;, &quot;delta&quot;) for (idx_sample in 1:BOOTSTRAP_SAMPLES) { # Generate a sample based on mod, and ensure a HMM can be estimated on it # with testing_params as initial parameters temp &lt;- pois.HMM.generate_estimable_sample(ns = DATA_SIZE, mod = list(m = m, lambda = lambda, gamma = gamma), testing_params = list(m = m, lambda = lambda_init, gamma = gamma_init))$natural_parameters # The values from gamma are taken columnwise natural_parameters &lt;- unlist(temp[PARAMS_NAMES]) len_par &lt;- length(natural_parameters) bootstrap_estimates[idx_sample, 1:len_par] &lt;- natural_parameters } # Lower and upper (2.5% and 97.5%) bounds q &lt;- apply(bootstrap_estimates, 2, function(par_estimate) { quantile(par_estimate, probs = c(0.025, 0.975)) }) PARAMS_NAMES &lt;- paste0(rep(&quot;lambda&quot;, m), 1:m) # Get row and column indexes for gamma instead of the default # columnwise index: the default indexes are 1:m for the 1st column, # then (m + 1):(2 * m) for the 2nd, etc... for (gamma_idx in 1:m ^ 2) { row &lt;- (gamma_idx - 1) %% m + 1 col &lt;- (gamma_idx - 1) %/% m + 1 row_col_idx &lt;- c(row, col) PARAMS_NAMES &lt;- c(PARAMS_NAMES, paste0(&quot;gamma&quot;, paste0(row_col_idx, collapse = &quot;&quot;))) } PARAMS_NAMES &lt;- c(PARAMS_NAMES, paste0(rep(&quot;delta&quot;, m), 1:m)) bootstrap_CI &lt;- data.frame(&quot;Parameter&quot; = PARAMS_NAMES, &quot;Estimate&quot; = c(lambda, gamma, delta), &quot;Lower bound&quot; = q[1, ], &quot;Upper bound&quot; = q[2, ]) print(bootstrap_CI, row.names = FALSE) # print(counter) # plot(x = 1:BOOTSTRAP_SAMPLES, y = nll) # hist(nll) # apply(bootstrap_estimates[, 1:2], 2, function(est) { # hist(est, breaks = &quot;FD&quot;) # }) # print(paste(&quot;Lack of convergence/missing results&quot;, counter2, counter1, &quot;times&quot;)) # myAIC[, &quot;pref&quot;] &lt;- ifelse(myAIC[, &quot;1state&quot;] &lt;= myAIC[, &quot;2state&quot;], 1, 2) # myBIC[, &quot;pref&quot;] &lt;- ifelse(myBIC[, &quot;1state&quot;] &lt;= myBIC[, &quot;2state&quot;], 1, 2) # print(paste(&quot;AIC prefers 1 state&quot;, sum(myAIC[, &quot;pref&quot;] == 1), &quot;times, and 2 states&quot;, sum(myAIC[, &quot;pref&quot;] == 2), &quot;times&quot;)) # print(paste(&quot;BIC prefers 1 state&quot;, sum(myBIC[, &quot;pref&quot;] == 1), &quot;times, and 2 states&quot;, sum(myBIC[, &quot;pref&quot;] == 2), &quot;times&quot;)) # # # print(paste(counter1, &quot;don&#39;t reach any result&quot;)) # # print(paste(&quot;conv codes:&quot;, conv1)) # print(paste(counter2, &quot;don&#39;t converge successfully&quot;)) # # print(paste(&quot;conv codes:&quot;, conv2)) # print(paste(counter3, &quot;parameters are NA&quot;)) # # print(paste(&quot;gamma over the threshold&quot;, counter_threshold_gamma, &quot;times&quot;)) # print(paste(&quot;lambda under the threshold&quot;, counter_threshold_lambda, &quot;times&quot;)) It should be noted that some bootstrap estimates can be very large or very small. One possible reason is that the randomly generated bootstrap sample might contain long chains of the same values, thus causing some probabilities in the TPM to be near the boundary 0 or 1. However, a large number of bootstrap samples lowers that risk since we leave out 5% of the most extreme values when computing the 95% CI. "]]
