# Multivariate Gaussian HMM

Multivariate Gaussian HMMs with `TMB` is a direct generalization of the univariate case from the previous section. We focus on the main differences.
Most notably, distribution parameters are changed from Normal mean vectors to matrices and we now have one covariance matrix for each state.
For the implementation, the main change is for the density function to go from `dnorm` to `dmvnorm` (and the random data generation functions from `rnorm` to `rmvnorm` for simulations) from the `mvtnorm` [@R-mvtnorm] package.

Many functions available in *[functions/norm_utils.R](#norm_utils)* have been adapted with the changes described for the multivariate Gaussian case in *[functions/mvnorm_utils.R](#mvnorm_utils.R)*.

As an example, the function to generate random data becomes
```{r mvnorm.HMM.generate.sample}
```

We detail below an example of the estimation of a two-state trivariate Gaussian HMM with TMB.

## Dataset & Parameters
To avoid issues regarding the choice of data, we simulate our own.

Let two multivariate Gaussian distributions $N(\bs{\mu_1}, \bs{\Sigma_1})$ and $N(\bs{\mu_2}, \bs{\Sigma_2})$ be defined with (rather arbitrary) parameters as follows.
\begin{equation*}
\bs{\mu_1} = (6, 8, 9) \quad \text{and }
\bs{\mu_2} = (1, 2, 3)
\end{equation*}

\begin{equation*}
\bs{\Sigma_1} =
\begin{pmatrix}
1.0 & 0.5 & 0.5\\
0.5 & 1.0 & 0.5\\
0.5 & 0.5 & 1.0
\end{pmatrix} \quad \text{ and }
\bs{\Sigma_2} =
\begin{pmatrix}
2.0 & 1.5 & 1.5\\
1.5 & 2.0 & 1.5\\
1.5 & 1.5 & 2.0
\end{pmatrix}.
\end{equation*}

Let us consider a stationary Markov chain with the following (also fairly random) TPM
\begin{equation*}
\bs{\Gamma} =
\begin{pmatrix}
0.95 & 0.05\\
0.15 & 0.85
\end{pmatrix}.
\end{equation*}

We generate 1000 data with the function above.

## Likelihood function
The Gaussian negative log-likelihood in TMB can be coded as
```{Rcpp 8mvnorm_hmm.cpp, code=readLines("code/mvnorm_hmm.cpp"), eval=FALSE}
```

and requires the following utility functions.
```{Rcpp 8mvnorm_utils.cpp, code=readLines("functions/mvnorm_utils.cpp"), eval=FALSE}
```

## Estimation
The estimation procedure is similar to before.
```{r 8example, cache=TRUE}
# Load packages and utility functions
source("code/packages.R")
source("functions/mvnorm_utils.R")

# Compile and load the objective function for TMB
TMB::compile("code/mvnorm_hmm.cpp")
dyn.load(TMB::dynlib("code/mvnorm_hmm"))

set.seed(123)

# Two states
m <- 2
# Trivariate Normal distribution
p <- 3

# One row of means per state, one column per dimension of the data
mu <- matrix(c(6, 8, 9,
               1, 2, 3), nrow = m, ncol = p, byrow = TRUE)
# Two covariance matrices
sigma1 <- matrix(c(1.0, 0.5, 0.5,
                   0.5, 1.0, 0.5,
                   0.5, 0.5, 1.0), nrow = p, ncol = p, byrow = TRUE)

sigma2 <- matrix(c(2.0, 1.5, 1.5,
                   1.5, 2.0, 1.5,
                   1.5, 1.5, 2.0), nrow = p, ncol = p, byrow = TRUE)
# We store them in an array for convenience, making them
# easily distinguishable at a glance when displayed
sigma <- array(c(sigma1, sigma2), dim = c(p, p, m))

# TPM
gamma <- matrix(c(0.95, 0.05,
                  0.15, 0.85), byrow = TRUE, nrow = m, ncol = m)

# Similarly to the Poisson case, we can generate data.
# Here, we generate a trivariate Gaussian sample of size 1000.
mod <- list(m = m,
            mu = mu,
            sigma = sigma,
            gamma = gamma)
TMBdata <- mvnorm.HMM.generate.sample(1000, mod)

# Parameters & covariates for TMB
# TMB requires a list
TMB_data <- list(x = TMBdata$data,
                 m = m)
# TMB requires the parameters to be either vectors, matrices, or arrays.
# For simplicity, we pass the parameters as a list of vectors and matrices.
pw <- mvnorm.HMM.pn2pw(m = m, mu = mu, sigma = sigma, gamma = gamma)

# Estimation
obj_tmb <- MakeADFun(data = TMB_data,
                     parameters = pw,
                     DLL = "mvnorm_hmm",
                     silent = TRUE)
nlminb(start = obj_tmb$par,
       objective = obj_tmb$fn,
       gradient = obj_tmb$gr,
       hessian = obj_tmb$he)
```

## Results
We show estimates and their standard errors.
Note that the matrix results (for $\bs{\delta}$, $\bs{\Gamma}$, and $\bs{\Sigma}$) are displayed in a column-wise format.
This can be verified by checking the more easily readable view of these estimates.
```{r 8obj-report}
summary(sdreport(obj_tmb), "report")
# More readable estimates
report <- obj_tmb$report()
report
```

## Bias
Since the data was simulated, the true parameters are known and the validity of the estimates can be checked.
To do this, we look at the maximum absolute percentage difference between estimates and true values.
```{r 8results-verification}
(t(report$mu) - mu) / mu
(report$sigma - sigma) / sigma
(report$gamma - gamma) / gamma
```
Differences are at most in the order of 10\% for values near 0. This is acceptable.
