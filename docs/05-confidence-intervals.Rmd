# Confidence intervals

```{r import-files, echo = FALSE, cache = FALSE}
library(knitr)
setwd(dir = "../")
suppressMessages(source("code/main.R"))
knitr::read_chunk('functions/utils.R')
```


From the parameters' ML estimates, we generate new data and re-estimate the parameters \Sexpr{BOOTSTRAP_SAMPLES} times.
From that list of new estimates we can get the 2.5th and 97.5th percentiles and get 95\% confidence intervals for the parameters.\

We show below how we get confidence intervals using bootstrap, based on the 2 state Poisson HMM estimates from above.

## Generating data

First, we need a function to generate random data from a HMM.
For readability and code maintenance, it is conventional to store procedures that will be used more than once into functions.

The data-generating function is defined in \citet[A.1.5 ~p.333]{zucchini}.
```{r generate_sample-original, eval=FALSE}
pois.HMM.generate_sample <- function(ns,mod) {
  mvect <- 1:mod$m
  state <- numeric(ns)
  state[1] <- sample(mvect, 1, prob = mod$delta)
  for (i in 2:ns) {
    state[i] <- sample(mvect, 1, prob = mod$gamma[state[i - 1], ])
  }
  x <- rpois(ns, lambda = mod$lambda[state])
  return(x)
}
```
If one wishes to retrieve the state sequence used to generate the data, an adjustment can be made.
```{r pois.HMM.generate_sample}
```
We return the results in a list to simplify usage, as the intuitive way (\texttt{c(x, state)}) would append the state sequence to the data.

* In practice, it happens that HMMs cannot be estimated on generated samples. To deal with this issue, we can generate a new sample as long as HMMs cannot be estimated on it with the help of this more robust function which can easily be adapted to different needs.
```{r pois.HMM.generate_estimable_sample}
```

## Relabeling HMM states

* When the model is estimated each time, we don't impose by default an order for the states.\
This can lead to the label switching problem, where states aren't ordered the same way in each model.
To address this, we re-ordered the states by ascending Poisson means.
Sorting the means is direct, however re-ordering the TPM is not as straightforward.
To do so, we take the permutations of the states given by the sorted Poisson means, and permute each row index and column index to its new value.
A function to achieve this is
```{r pois.HMM.label.order}
```

Let's show an example to understand the process.
For readability, the TPM is filled with row and column indexes instead of probabilities.
```{r relabel}
lambda <- c(30, 10, 20)
gamma <- matrix(c(11, 12, 13,
                  21, 22, 23,
                  31, 32, 33), byrow = TRUE, ncol = 3)
pois.HMM.label.order(m = 3, lambda, gamma)
```

State 1 has been relabeled state 3, state 3 became state 2, and state 2 became state 1.

## Bootstrap code

```{r bootstrap-code, eval = FALSE}
set.seed(123)
library(TMB)
TMB::compile("code/poi_hmm.cpp")
dyn.load(dynlib("code/poi_hmm"))
source("functions/utils.R")
m <- 2
load("data/tinnitus.RData")
TMB_data <- list(x = tinn_data, m = m)

# Initial set of parameters
lambda_init <- c(1, 3)
gamma_init <- matrix(c(0.8, 0.2,
                       0.2, 0.8), byrow = TRUE, nrow = m)

# Turn them into working parameters
parameters <- pois.HMM.pn2pw(m, lambda_init, gamma_init)

# Build the TMB object
obj_tmb <- MakeADFun(TMB_data, parameters,
                     DLL = "poi_hmm", silent = TRUE)

# Optimize
mod_tmb <- nlminb(start = obj_tmb$par,
                  objective = obj_tmb$fn,
                  gradient = obj_tmb$gr,
                  hessian = obj_tmb$he)


# Bootstrap procedure
bootstrap_estimates <- data.frame()
DATA_SIZE <- length(tinn_data)
# Set how many parametric bootstrap samples we create
BOOTSTRAP_SAMPLES <- 10

# MLE
ML_working_estimates <- obj_tmb$env$last.par.best
ML_natural_estimates <- obj_tmb$report(ML_working_estimates)
lambda <- ML_natural_estimates$lambda
gamma <- ML_natural_estimates$gamma
delta <- ML_natural_estimates$delta

PARAMS_NAMES <- c("lambda", "gamma", "delta")
for (idx_sample in 1:BOOTSTRAP_SAMPLES) {
  # Generate a sample based on mod, and ensure a HMM can be estimated on it
  # with testing_params as initial parameters
  temp <- pois.HMM.generate_estimable_sample(ns = DATA_SIZE,
                                             mod = list(m = m,
                                                        lambda = lambda,
                                                        gamma = gamma),
                                             testing_params = list(m = m,
                                                                   lambda = lambda_init,
                                                                   gamma = gamma_init))$natural_parameters
  # The values from gamma are taken columnwise
  natural_parameters <- unlist(temp[PARAMS_NAMES])
  len_par <- length(natural_parameters)
  bootstrap_estimates[idx_sample, 1:len_par] <- natural_parameters
}

# Lower and upper (2.5% and 97.5%) bounds
q <- apply(bootstrap_estimates, 2, function(par_estimate) {
  quantile(par_estimate, probs = c(0.025, 0.975))
})

PARAMS_NAMES <- paste0(rep("lambda", m), 1:m)
# Get row and column indexes for gamma instead of the default
# columnwise index: the default indexes are 1:m for the 1st column,
# then (m + 1):(2 * m) for the 2nd, etc...
for (gamma_idx in 1:m ^ 2) {
  row <- (gamma_idx - 1) %% m + 1
  col <- (gamma_idx - 1) %/% m + 1
  row_col_idx <- c(row, col)
  PARAMS_NAMES <- c(PARAMS_NAMES,
                    paste0("gamma",
                           paste0(row_col_idx, collapse = "")))
}
PARAMS_NAMES <- c(PARAMS_NAMES,
                  paste0(rep("delta", m), 1:m))

bootstrap_CI <- data.frame("Parameter" = PARAMS_NAMES,
                           "Estimate" = c(lambda, gamma, delta),
                           "Lower bound" = q[1, ],
                           "Upper bound" = q[2, ])
print(bootstrap_CI, row.names = FALSE)
# print(counter)
# plot(x = 1:BOOTSTRAP_SAMPLES, y = nll)
# hist(nll)
# apply(bootstrap_estimates[, 1:2], 2, function(est) {
#   hist(est, breaks = "FD")
# })
# print(paste("Lack of convergence/missing results", counter2, counter1, "times"))
# myAIC[, "pref"] <- ifelse(myAIC[, "1state"] <= myAIC[, "2state"], 1, 2)
# myBIC[, "pref"] <- ifelse(myBIC[, "1state"] <= myBIC[, "2state"], 1, 2)
# print(paste("AIC prefers 1 state", sum(myAIC[, "pref"] == 1), "times, and 2 states", sum(myAIC[, "pref"] == 2), "times"))
# print(paste("BIC prefers 1 state", sum(myBIC[, "pref"] == 1), "times, and 2 states", sum(myBIC[, "pref"] == 2), "times"))
# 
# 
# print(paste(counter1, "don't reach any result"))
# # print(paste("conv codes:", conv1))
# print(paste(counter2, "don't converge successfully"))
# # print(paste("conv codes:", conv2))
# print(paste(counter3, "parameters are NA"))
# # print(paste("gamma over the threshold", counter_threshold_gamma, "times"))
# print(paste("lambda under the threshold", counter_threshold_lambda, "times"))
```


It should be noted that some bootstrap estimates can be very large or very small.
One possible reason is that the randomly generated bootstrap sample might contain long chains of the same values, thus causing some probabilities in the TPM to be near the boundary 0 or 1.
However, a large number of bootstrap samples lowers that risk since we leave out 5\% of the most extreme values when computing the 95\% CI.